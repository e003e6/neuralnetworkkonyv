A jegyzet a [*Harrison Kinsley & Daniel Kukieła - Neural Networks from Scratch in Python*](https://nnfs.io/) könyv alapján készült. 

5 - Backpropagation: folyamatban...

---

A jegyzet célja, hogy a neurális hálózatok megértésével lehetőségem nyíljon az evolúciós folyamatok modellezésére a neurális matematikai modellek felhasználásával. 

A számítógépes architektúrák jól ismert alapelve, hogy hardver és szoftver szinten is megvalósítható a vas programozása, és (ön)szervezett munkára bírhatók a tranzisztorok milliárdjai. Ám a magasabb absztrakciós szinten való programozáshoz egy forráskód és egy fordító program szükséges, ami a hardver (anya)nyelvére fordítja a (több értelemben is) magasabb szinten megírt kódot. A hardver szintű programozást a tranzisztorok kapcsolásának felépítése adja. 

Ha követjük az agy-számítógép analógiát (és miért ne tennénk?), ez az univerzális szabály azt eredményezi a tudattal, organikus neurális hálózatokkal rendelkező szervezeteknél, hogy vagy van az agyban egy terület, ami ezt a fordítóprogramot és az "élet kódját" tartalmazza - ami így egy külön evolúciós mechanizmus (vagy előre kódolt szabályszerűség) működtethet (mint ahogy a programozó és a lapka tervező szétválik) - vagy pedig a hardver architektúrájába van kódolva a vasat működtető kód, és egy tervező, evolúciós folyamat formálhatja működését. A fizikai (szerves) élet evolúciója már bizonyítást nyert sok-sok éve, de a tudati szinten csak mint következtetés tárgya használják. 

Ha nem találunk az agyban egy fordítóprogramnak megfelelő egységet és egy forráskódot akkor feltételezhető a második eset. Ami pedig egyértelműen azt jelenti, hogy a neuronhálózat topológiájának következménye a tudat. 

De mind ez mit sem számít: a számítógépes architektúrák tudománya bebizonyította, hogy a két megvalósítás működését tekintve teljes mértékben megfeleltethető egymással. A döntő különbség az eredet. Ha a neuronok topológiája eredményezi a tudatot akkor az evolúció paradigmája szent és sérthetetlen. A második eset kissé bonyolultabb, és ketté válik. Első esetben egy "hard" kódolt algoritmust feltételez, ami mint kernel működteti a fizikai testet, és még fontosabb magát az evolúciót is. Talán ennek a kódnak az eredménye az alkalmazkodás szabályszerűsége. De akkor ki írta ezt a kódot?  Ez egy felsőbb erőt feltételez legyen az Isten, vagy akár egy programozó a szimuláción kívül...  A második eset az agyat úgy ábrázolja, mint egy egyszerű számítógép, ami alapműveletek elvégzésére képes. Az „élet kódja” ezekre az alapműveletekre fordul le, futásának hardvere az emberi agy, az IO pedig az érzékszervek és az izom mozgató (motoros) idegek. Az evolúció által a számítógép és a kód is külön fejlődik: a számítógép egyre hatékonyabb lesz számítási kapacitását tekintve, mind addig ameddig a túl nagy agy nem jelent túlélési hátrányt; a kód pedig a túlélés és egyben tudat szekvenciáját hordozza. Egyre jobban kifinomul a „racionalitás” mind addig ameddig a túl sok gondolkodás nem jelent túlélési hátrányt. A kettő együttes működésének eredménye a tudat: a hardver és a szoftver.

Én hiszem, hogy a neuronok kapcsolása egyben hordozza a kódot is, vagyis a topológia eredménye a tudat. Az egyes sejtekről már nagyjából tudjuk, hogy működnek, önszerveződésen működő apró egységek egymásra ható kapcsolata a nagy kérdés.

A statisztikai neurális hálózatok több millió paraméterrel rendelkező nemlineáris függvények (a függvények láncolata megfelel egy nagy függvénynek sok paraméterrel). A betanítás során pedig azokat a paraméter kombinációkat kísérletezgetjük ki, ami egy olyan függvényt eredményez, ami adott x értékhez az általunk „betanított” (beállított) y értéket adja. Bízva a mára már elérhető „végtelen” számítási kapacitásban megtehetjük, hogy a több millió paraméter mindegyikét apró módosításokkal, majd a kimenetre adott válasz ellenőrzésével finomra hangoljuk. Az élet nem tehette meg, hogy ilyen kísérletező játékot játsszon. Az élet nem vánszorog. Nem engedheti meg magának a hibát: a hibának erősítenie kell a rendszert különben kihalásra van ítélve. 

Ez a csodálatosan szakbarbár hozzáállás (neuronoknak nevezett függvények rétegei) sosem lesznek képesek tudatot létrehozni. Hatékonyságát kizárólag az adja, hogy (a valós működésében a neuronok nyomát sem találjuk) mátrix-okra egyszerűsítődik a matek, amik nagyon hatékonyan feldolgozhatóak.

A nemlineáris műveletsoron alapuló feladatvégzés teszi az organikus neurális hálózatokat olyan hatékonnyá. Egy processzor erősen leegyszerűsítve egymás utáni numerikus műveleteket tud megoldani. Az agyról pedig tudjuk, hogy egyidőben haladó, nem órajel szerűen szinkronizált impulzusok eredménye. Ez okozza a valóságos szimuláció nehézségét. El kell felejteni a függvényeken alapuló modellezési eljárásokat és a számítógépet az óriási sok gigahertzes órajel szinkronizálással együtt új féleképpen kell felhasználni. Kell hogy legyen egy olyan matematikai egyenlet, ami megadja, hogy mekkora párhuzamos számítási kapacitással váltható ki az agy diszinkron működéséből eredő hatékonyság felőnye. (A több magos számítás természetesen jelen értelemben nem valós párhuzamosság, mivel ezek egybe épített, de elszeparált lineáris műveleti egységek; erre jó példa, hogy a memóriát egyidejűleg csak egy mag használhatja.) E képlet megadná, hogy a mai technológiával bele lehet-e vágni, egy klasszikus (Neumann féle) számítógéppel tudatot létrehozni. Tudva, hogy (számítástechnikai léptékkel) milyen sok időre van szüksége egy neuronnak, hogy ingerlés után újra (megfelelően) működni tudjon egyáltalán nem elképzelhető, hogy soros feladatvégzéssel is szimulálható egy egyszerűbb tudat. (Bár a neuronok megfelelő helyreállási ideje felveti azt a kérdést, hogy talán a nem megfelelő működés ugyan olyan fontos mint a megfelelő.)

A komplex rendszerek, mint az agy, fő működési tulajdonsága az önhasonulás, vagyis az iterálás: a változó helyére az eredményt visszacsatoljuk; mondja a matematika. (Véleményem szerint) a komplex rendszerek komplexitását a „részeredmények” módosításának lehetősége adja. Adott inputtal rendelkező neuron kimenetét befolyásolhatja egy időközben megjelenő még egy bemeneti jel. Ez pedig (ha egy koordináta rendszeren nézzük a kimenetet), egy olyan komplex függvényt ír le, amit matematikai állandókkal beállítani lehetetlen, vagy pedig (és ez a lényeg) minden egyes neuron egy saját statisztikai neurális hálózat, ami persze nonszensz. A „végtelen” „görbülettel” rendelkező „függvényeknek” létezniük kell egy nem matematikai megvalósításának, ami a már fent említett valós párhuzamosság eredménye, amit modellezni nem tudunk (jelenlegi) számítógépes módszereinkkel, de nem kizárt, hogy mégis lehetséges matematikai nyelvre lefordítani és így modellezhetővé is válik. 

A statisztikai neurális hálózatokat a nemlineáris aktivációs függvények kombinációja teszi sok „görbülettel” rendelkező kimeneti függvénnyé. Ezáltal egy teljes neurális hálózat egy komplex függvény. De a valóságban (ha a fent leírtakat elfogadjuk) minden neuron egy ilyen komplex függvény. A kérdés egyszerű: milyen matematikában nem ismert (organikus) algoritmus (nevezzük Generalized Output Determinator algoritmusnak) képes nem függvények láncolataként végtelen görbülettel leírható kimenetek produkálására, és még fontosabb: hogyan lehet ezt lineáris számítással modellezni.

A neuron ágens alapú modellezése biztosan nem megoldás, ugyanis a sejtek az evolúció által kifejlesztett eszközök, gépek amik adott jelre adott reakciót adnak. A sejtmagban tárolt DNS a (szerves) testet felépítő fehérjék „tervrajzait” (valójában gyártási folyamatát) tárolja, ezek a tervrajzok azok amik képesek a mutációra (öröklődéskor és működés közben is). Az öröklődéskor egyszerűen csak párosítjuk két egyed DNS-ét (fele innen-fele onnan (de hogyan választunk?)), majd az evolúció hozzáad egy kis variációt (mutáció) a képletbe és ennek eredménye az új egyed (fehérjéinek) tervrajza, DNS-e. (De ha ez így működik akkor egy rakás felesleges gén-nek kell lennie, amik sosem aktiválódnak: a páfrány nagyon régi faj = nagyon sok génje van ??)

A tervrajz megadja egy eszköz működési módját (lehetőségeit), de semmit nem mond a működtetéséről. A működést az input molekulák határozzák meg. Ez a két tulajdonság a (számítógépes) modellezés szempontjából igen hasznos. 

A gén egy adott fehérje gyártási folyamatának leírása, a sejt működését pedig az őt felépítő fehérjék határozzák meg. A biológiától elszakadva ez azt jelentheti, hogy szükségünk van különböző működési elvek szerint működő dfehérjékre („digitális fehérje”) amik (felejtsük el a biológiát) működését adott hosszúságú gének kombinációi határozzák meg. Egyszerűsítsük le a képletet: dfehérjék = paraméterek, a paramétereket az evolúciós (= variációs?) folyamat határozza meg (nem pedig a tanítás folyamata). A statisztikai neurális hálózatokhoz hasonlóan a neuron kimenetét a paraméterek és az input adatok kombinációja határozza meg a Generalized Output Determinator algoritmus szerint. 

A legtöbb (ma használt) evolúciós szimulációban az evolúció folyamatát társadalmi, populációs szinten modellezik, vagyis létrehoznak rakás variációval egyedeket, az egyedekhez fittségi értéket határoznak egy szimulált versenyhelyzet eredménye képen majd a legnagyobb pontszámúakat tovább engedik a következő körbe, vagy a legkevesebb pontszámú egyedeket eltávolítják és helyükre pszeudó véletlen generátorral új variációjú egyedet raknak. A valóság nyilvánvalóan nem így működik, ez a módszer az élet legfontosabb szabályát hagyja figyelmen kívül: a hibának erősítenie kell a rendszert különben kihalásra van ítélve. Fogjuk fel az evolúciót úgy mint egy blokkláncot: a genesis blokk az élet kezdete és nem eltávolítható a blokklánc történelméből. Az egyedszintű evolúciós modellezés alapja a hiba előnnyé formálása. Ennek következménye,  hogy az evolúciós folyamat nem általános szabályszerűség (hacsak nem Isteni eredetű) a genesis egyed „életképességének” önreprodukciójának módszere, tulajdonsága, algoritmusa. 

Ha az evolúciót úgy fogjuk fel mint reprodukciós algoritmus akkor hirtelen generációs iterálás nélkül is modellezhetőnek kell lennie. Véletlenszerűséget ott használunk, ahol nem értjük a bonyolult rendszereket. Ha létezik alkalmazkodó mutáció (már pedig elég valószínű) akkor ez a folyamat maga az evolúció. Emiatt generációs iteráció helyett használhatunk egy egyszerű evolúciós korrekciót a gén állomány frissítésére és ezt megtehetjük minden egyes reakciót követően. Ezt persze csak úgy tehetjük meg ha központi, kollektív DNS-t használunk. 

A számítógépes bejövő numerikus adat nem feleltethető molekuláknak, logikus, hogy (a sejtek működését alapul véve) nem numerikus adatot adok át a következő neuronnak hanem különböző állapotokkal rendelkezhető dmolekulákat. Ezek aktiválják dfehérjéket (paramétereket) a paraméterek kombinációja pedig meghatározza a kimenetet. Az idegsejtek különböző típusai eltérő fehérjéket tartalmaznak és más génekből épülnek fel, ami hozzájárul a funkcionális sokféleségükhöz. Minden típusú neuron máshogy reagál egy bemeneti (dmolekula) jelre. Különböző fajta neuronok különböző fajta működéseket eredményeznek mivel a fehérjék (paraméterek) mások. A paraméter nem egy konstans, hanem inkább egy dmolekulára adott reakció. A környezet (bemeneti molekula) választja ki, hogy melyik gének aktiválódjanak (ha nincsen ilyen akkor milyen (ilyen) fehérjék készüljenek). Ezek kombinációja pedig adott reakcióra kényszeríti a neuront.

Én a betanítás folyamatát ketté választanám, nevezzük mondjuk: keltetés és tanítás. A keltetés folyamata a fehérjék létrehozása. A fehérjék a szimulációban közvetlenül reakciók. A tanítás a valós problémára való "kondicionálás": feladat specifikus adatokra illesztés. A tanulás folyamata a kapcsolatok kialakítása.



